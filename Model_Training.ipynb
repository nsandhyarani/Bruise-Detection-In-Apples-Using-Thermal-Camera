{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pip install tensorflow==2.16.1"
      ],
      "metadata": {
        "id": "3Hk1TQztMIzs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1mFFh5CAN1Zz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JevrrcRobOqO",
        "outputId": "55373806-3e20-40ee-e3c1-6818ffdc22c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRdyBqtIbXJO",
        "outputId": "25f5d945-2a46-4f9e-90dd-bfbd19708340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw2Hg0U3cNc5",
        "outputId": "950f3e6e-46e1-42e8-aff5-77ce7d047df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7.1\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "print(matplotlib.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aaT5EUlJN562",
        "outputId": "aa3f4c53-b36c-4405-b66d-69d78761dbad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pickle\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "\n",
        "# Load and preprocess data (same as before)\n",
        "\n",
        "# Load data\n",
        "bruised_data = pd.read_csv('ab1.csv')\n",
        "non_bruised_data = pd.read_csv('anb1.csv')\n",
        "\n",
        "# Ensure all data has the same number of columns (features)\n",
        "num_features = min(bruised_data.shape[1], non_bruised_data.shape[1])\n",
        "bruised_data = bruised_data.iloc[:, :num_features]\n",
        "non_bruised_data = non_bruised_data.iloc[:, :num_features]\n",
        "\n",
        "# Add labels\n",
        "bruised_data['label'] = 0  # Bruised\n",
        "non_bruised_data['label'] = 1  # Non-bruised\n",
        "\n",
        "# Combine the datasets\n",
        "all_data = pd.concat([bruised_data, non_bruised_data], axis=0)\n",
        "\n",
        "# Shuffle the combined data\n",
        "all_data_shuffled = all_data.sample(frac=1, random_state=42)  # Shuffle all data\n",
        "\n",
        "# Separate features and labels from shuffled data\n",
        "X = all_data_shuffled.iloc[:, 1:-1].values  # Assuming the first column isn't relevant; adjust if needed\n",
        "y = all_data_shuffled.iloc[:, -1].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Save the scaler for later use\n",
        "pickle.dump(scaler, open('scaler2.pkl', 'wb'))\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "num_classes = 2  # Binary classification\n",
        "y_resampled = to_categorical(y_resampled, num_classes=num_classes)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply ADASYN to balance the dataset\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_resampled, y_resampled = adasyn.fit_resample(X, y)\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "num_classes = 2\n",
        "y_resampled = to_categorical(y_resampled, num_classes=num_classes)\n",
        "\n",
        "# Define the model\n",
        "def create_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Dense(256, activation='relu', input_shape=input_shape, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Implement k-fold cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store the results of each fold\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_resampled, np.argmax(y_resampled, axis=1)), 1):\n",
        "    print(f'Fold {fold}')\n",
        "\n",
        "    X_train, X_val = X_resampled[train_index], X_resampled[val_index]\n",
        "    y_train, y_val = y_resampled[train_index], y_resampled[val_index]\n",
        "\n",
        "    model = create_model((X_train.shape[1],))\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights = {0: len(y_train) / (2 * np.sum(y_train[:, 0])),\n",
        "                     1: len(y_train) / (2 * np.sum(y_train[:, 1]))}\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=32,\n",
        "        epochs=200,\n",
        "        validation_data=(X_val, y_val),\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred_prob = model.predict(X_val)\n",
        "\n",
        "    # Find optimal threshold\n",
        "    thresholds = np.arange(0, 1, 0.01)\n",
        "    f1_scores_threshold = []\n",
        "    for threshold in thresholds:\n",
        "        y_pred_labels = (y_pred_prob[:, 1] > threshold).astype(int)\n",
        "        f1_scores_threshold.append(f1_score(np.argmax(y_val, axis=1), y_pred_labels))\n",
        "\n",
        "    optimal_threshold = thresholds[np.argmax(f1_scores_threshold)]\n",
        "    print(f\"Optimal threshold: {optimal_threshold}\")\n",
        "\n",
        "    # Use optimal threshold for predictions\n",
        "    y_pred_labels = (y_pred_prob[:, 1] > optimal_threshold).astype(int)\n",
        "    y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred_labels)\n",
        "    precision = precision_score(y_true, y_pred_labels)\n",
        "    recall = recall_score(y_true, y_pred_labels)\n",
        "    f1 = f1_score(y_true, y_pred_labels)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred_labels)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Print average results\n",
        "print(\"\\nAverage Results:\")\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f} (+/- {np.std(accuracies):.4f})\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f} (+/- {np.std(precisions):.4f})\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f} (+/- {np.std(recalls):.4f})\")\n",
        "print(f\"F1 Score: {np.mean(f1_scores):.4f} (+/- {np.std(f1_scores):.4f})\")\n",
        "\n",
        "# Train the final model on all data\n",
        "final_model = create_model((X_resampled.shape[1],))\n",
        "final_model.fit(\n",
        "    X_resampled, y_resampled,\n",
        "    batch_size=32,\n",
        "    epochs=200,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Save the final model\n",
        "final_model.save('model2.h5')\n",
        "\n",
        "# Save the scaler\n",
        "pickle.dump(scaler, open('scaler2.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "vbaQbH-2dX8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pickle\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = str(42)\n",
        "\n",
        "# Your data loading and preprocessing code here...\n",
        "\n",
        "# Compute confusion matrix and other metrics for each fold\n",
        "confusion_matrices = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X_resampled, np.argmax(y_resampled, axis=1)), 1):\n",
        "    print(f'Fold {fold}')\n",
        "\n",
        "    X_train, X_val = X_resampled[train_index], X_resampled[val_index]\n",
        "    y_train, y_val = y_resampled[train_index], y_resampled[val_index]\n",
        "\n",
        "    model = create_model((X_train.shape[1],))\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights = {0: len(y_train) / (2 * np.sum(y_train[:, 0])),\n",
        "                     1: len(y_train) / (2 * np.sum(y_train[:, 1]))}\n",
        "\n",
        "    # Callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=32,\n",
        "        epochs=200,\n",
        "        validation_data=(X_val, y_val),\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stopping, reduce_lr]\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred_prob = model.predict(X_val)\n",
        "\n",
        "    # Find optimal threshold\n",
        "    thresholds = np.arange(0, 1, 0.01)\n",
        "    f1_scores_threshold = []\n",
        "    for threshold in thresholds:\n",
        "        y_pred_labels = (y_pred_prob[:, 1] > threshold).astype(int)\n",
        "        f1_scores_threshold.append(f1_score(np.argmax(y_val, axis=1), y_pred_labels))\n",
        "\n",
        "    optimal_threshold = thresholds[np.argmax(f1_scores_threshold)]\n",
        "    print(f\"Optimal threshold: {optimal_threshold}\")\n",
        "\n",
        "    # Use optimal threshold for predictions\n",
        "    y_pred_labels = (y_pred_prob[:, 1] > optimal_threshold).astype(int)\n",
        "    y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred_labels)\n",
        "    confusion_matrices.append(cm)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred_labels)\n",
        "    precision = precision_score(y_true, y_pred_labels)\n",
        "    recall = recall_score(y_true, y_pred_labels)\n",
        "    f1 = f1_score(y_true, y_pred_labels)\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Average confusion matrix\n",
        "avg_confusion_matrix = np.mean(confusion_matrices, axis=0).astype(int)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(avg_confusion_matrix, annot=True, cmap='Blues', fmt='d', xticklabels=['Non-Bruised', 'Bruised'], yticklabels=['Non-Bruised', 'Bruised'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Average Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print average results\n",
        "average_accuracy = np.mean(accuracies)\n",
        "average_precision = np.mean(precisions)\n",
        "average_recall = np.mean(recalls)\n",
        "average_f1_score = np.mean(f1_scores)\n",
        "\n",
        "print(\"\\nAverage Results:\")\n",
        "print(f\"Accuracy: {average_accuracy:.4f} (+/- {np.std(accuracies):.4f})\")\n",
        "print(f\"Precision: {average_precision:.4f} (+/- {np.std(precisions):.4f})\")\n",
        "print(f\"Recall: {average_recall:.4f} (+/- {np.std(recalls):.4f})\")\n",
        "print(f\"F1 Score: {average_f1_score:.4f} (+/- {np.std(f1_scores):.4f})\")\n",
        "print(f\"\\nAverage Confusion Matrix:\\n{avg_confusion_matrix}\")\n",
        "print(f\"True Positives (TP): {avg_confusion_matrix[1, 1]}\")\n",
        "print(f\"True Negatives (TN): {avg_confusion_matrix[0, 0]}\")\n",
        "print(f\"False Positives (FP): {avg_confusion_matrix[0, 1]}\")\n",
        "print(f\"False Negatives (FN): {avg_confusion_matrix[1, 0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HJtReOb1biry",
        "outputId": "ed35078e-4fef-4e64-f7cc-dd7e830e4dd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 5s 38ms/step - loss: 4.1975 - accuracy: 0.5142 - val_loss: 3.8231 - val_accuracy: 0.4659 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.9861 - accuracy: 0.6023 - val_loss: 3.7865 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.8605 - accuracy: 0.6506 - val_loss: 3.7331 - val_accuracy: 0.5227 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.9118 - accuracy: 0.5994 - val_loss: 3.6790 - val_accuracy: 0.5568 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.7299 - accuracy: 0.6676 - val_loss: 3.6262 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.6497 - accuracy: 0.6733 - val_loss: 3.5718 - val_accuracy: 0.6818 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5496 - accuracy: 0.6989 - val_loss: 3.5122 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.5558 - accuracy: 0.7017 - val_loss: 3.4602 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.3577 - accuracy: 0.7528 - val_loss: 3.4123 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.3793 - accuracy: 0.6875 - val_loss: 3.3567 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.3044 - accuracy: 0.7131 - val_loss: 3.3027 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.2280 - accuracy: 0.7500 - val_loss: 3.2443 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.1754 - accuracy: 0.7358 - val_loss: 3.1939 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.0344 - accuracy: 0.7898 - val_loss: 3.1557 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.0339 - accuracy: 0.7557 - val_loss: 3.1093 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.9633 - accuracy: 0.7614 - val_loss: 3.0481 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8914 - accuracy: 0.7983 - val_loss: 2.9858 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.8520 - accuracy: 0.8040 - val_loss: 2.9287 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.7639 - accuracy: 0.8182 - val_loss: 2.8771 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.7453 - accuracy: 0.8068 - val_loss: 2.8139 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.7042 - accuracy: 0.8097 - val_loss: 2.7576 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.5802 - accuracy: 0.8551 - val_loss: 2.7147 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.5574 - accuracy: 0.8409 - val_loss: 2.6629 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.5159 - accuracy: 0.8239 - val_loss: 2.6220 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.4712 - accuracy: 0.8239 - val_loss: 2.5536 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4654 - accuracy: 0.8182 - val_loss: 2.4964 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.4360 - accuracy: 0.8011 - val_loss: 2.4642 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.3908 - accuracy: 0.8068 - val_loss: 2.4168 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3675 - accuracy: 0.7926 - val_loss: 2.3486 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.2827 - accuracy: 0.8125 - val_loss: 2.3486 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1651 - accuracy: 0.8466 - val_loss: 2.2961 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1548 - accuracy: 0.8324 - val_loss: 2.2254 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1021 - accuracy: 0.8409 - val_loss: 2.1938 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1530 - accuracy: 0.8011 - val_loss: 2.1821 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0513 - accuracy: 0.8438 - val_loss: 2.1028 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.9836 - accuracy: 0.8494 - val_loss: 2.0730 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.9335 - accuracy: 0.8523 - val_loss: 2.0391 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.8805 - accuracy: 0.8778 - val_loss: 2.0057 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.9086 - accuracy: 0.8438 - val_loss: 1.9503 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.8048 - accuracy: 0.8835 - val_loss: 1.9558 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.8096 - accuracy: 0.8438 - val_loss: 1.8774 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.7972 - accuracy: 0.8494 - val_loss: 1.8514 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 1.7665 - accuracy: 0.8494 - val_loss: 1.7968 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7732 - accuracy: 0.8210 - val_loss: 1.7648 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.6147 - accuracy: 0.9006 - val_loss: 1.7597 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.5975 - accuracy: 0.8750 - val_loss: 1.6806 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.6064 - accuracy: 0.8722 - val_loss: 1.6796 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.5443 - accuracy: 0.8665 - val_loss: 1.6574 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.5244 - accuracy: 0.8864 - val_loss: 1.6152 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.5041 - accuracy: 0.8551 - val_loss: 1.5996 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4445 - accuracy: 0.9006 - val_loss: 1.5527 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4665 - accuracy: 0.8835 - val_loss: 1.5241 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4045 - accuracy: 0.9034 - val_loss: 1.5543 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3264 - accuracy: 0.9176 - val_loss: 1.5170 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3558 - accuracy: 0.8892 - val_loss: 1.4616 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2958 - accuracy: 0.8864 - val_loss: 1.4404 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3504 - accuracy: 0.8608 - val_loss: 1.4161 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.2689 - accuracy: 0.8892 - val_loss: 1.3831 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2754 - accuracy: 0.8778 - val_loss: 1.3549 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2148 - accuracy: 0.8864 - val_loss: 1.4270 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1865 - accuracy: 0.9091 - val_loss: 1.3602 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2059 - accuracy: 0.8807 - val_loss: 1.3406 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.1397 - accuracy: 0.8949 - val_loss: 1.2222 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1282 - accuracy: 0.8949 - val_loss: 1.2812 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1309 - accuracy: 0.9062 - val_loss: 1.2302 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1195 - accuracy: 0.8835 - val_loss: 1.1876 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0833 - accuracy: 0.9006 - val_loss: 1.1972 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0582 - accuracy: 0.8977 - val_loss: 1.2074 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0268 - accuracy: 0.9062 - val_loss: 1.2030 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0146 - accuracy: 0.9006 - val_loss: 1.1191 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9731 - accuracy: 0.9034 - val_loss: 1.1966 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9372 - accuracy: 0.9233 - val_loss: 1.1207 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9398 - accuracy: 0.9062 - val_loss: 1.0601 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9339 - accuracy: 0.8977 - val_loss: 1.0440 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9150 - accuracy: 0.8920 - val_loss: 1.0208 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9230 - accuracy: 0.8949 - val_loss: 1.0062 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.8617 - accuracy: 0.8977 - val_loss: 0.9825 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.8752 - accuracy: 0.9176 - val_loss: 0.9745 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.8450 - accuracy: 0.8977 - val_loss: 0.9993 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.8681 - accuracy: 0.9176 - val_loss: 1.0426 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.7865 - accuracy: 0.9233 - val_loss: 0.9486 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.8317 - accuracy: 0.8835 - val_loss: 0.9181 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.8257 - accuracy: 0.9006 - val_loss: 0.9103 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.8107 - accuracy: 0.9034 - val_loss: 0.8902 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.8491 - accuracy: 0.8835 - val_loss: 0.9286 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.7506 - accuracy: 0.9176 - val_loss: 0.8827 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.7805 - accuracy: 0.8920 - val_loss: 0.8630 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.7567 - accuracy: 0.9205 - val_loss: 0.8581 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.7223 - accuracy: 0.9034 - val_loss: 0.8782 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.7531 - accuracy: 0.8920 - val_loss: 0.8526 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.7286 - accuracy: 0.9119 - val_loss: 0.8148 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.7167 - accuracy: 0.9119 - val_loss: 0.7930 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.7095 - accuracy: 0.9034 - val_loss: 0.8287 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.6577 - accuracy: 0.9375 - val_loss: 0.8188 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.6757 - accuracy: 0.9062 - val_loss: 0.7518 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6538 - accuracy: 0.9148 - val_loss: 0.7541 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.6156 - accuracy: 0.9375 - val_loss: 0.7582 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.6454 - accuracy: 0.8977 - val_loss: 0.7171 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6785 - accuracy: 0.9119 - val_loss: 0.7775 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6401 - accuracy: 0.9062 - val_loss: 0.7263 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6680 - accuracy: 0.8892 - val_loss: 0.7533 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6365 - accuracy: 0.9006 - val_loss: 0.7911 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6608 - accuracy: 0.8807 - val_loss: 0.8575 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.9091 - val_loss: 0.7762 - val_accuracy: 0.7727 - lr: 2.0000e-04\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5823 - accuracy: 0.9318 - val_loss: 0.7123 - val_accuracy: 0.8068 - lr: 2.0000e-04\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5745 - accuracy: 0.9261 - val_loss: 0.7078 - val_accuracy: 0.8068 - lr: 2.0000e-04\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5620 - accuracy: 0.9119 - val_loss: 0.7058 - val_accuracy: 0.8523 - lr: 2.0000e-04\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5339 - accuracy: 0.9432 - val_loss: 0.7015 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5637 - accuracy: 0.9233 - val_loss: 0.6922 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5251 - accuracy: 0.9545 - val_loss: 0.6872 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5549 - accuracy: 0.9347 - val_loss: 0.6886 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5456 - accuracy: 0.9318 - val_loss: 0.7034 - val_accuracy: 0.8182 - lr: 2.0000e-04\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5346 - accuracy: 0.9375 - val_loss: 0.6957 - val_accuracy: 0.8182 - lr: 2.0000e-04\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5219 - accuracy: 0.9517 - val_loss: 0.7038 - val_accuracy: 0.8295 - lr: 2.0000e-04\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5601 - accuracy: 0.9205 - val_loss: 0.6911 - val_accuracy: 0.8182 - lr: 2.0000e-04\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5215 - accuracy: 0.9432 - val_loss: 0.6943 - val_accuracy: 0.8182 - lr: 4.0000e-05\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5278 - accuracy: 0.9403 - val_loss: 0.6886 - val_accuracy: 0.8182 - lr: 4.0000e-05\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5462 - accuracy: 0.9318 - val_loss: 0.6821 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4847 - accuracy: 0.9574 - val_loss: 0.6807 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5198 - accuracy: 0.9403 - val_loss: 0.6835 - val_accuracy: 0.8182 - lr: 4.0000e-05\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4924 - accuracy: 0.9517 - val_loss: 0.6832 - val_accuracy: 0.8182 - lr: 4.0000e-05\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5033 - accuracy: 0.9432 - val_loss: 0.6801 - val_accuracy: 0.8182 - lr: 4.0000e-05\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5506 - accuracy: 0.9233 - val_loss: 0.6768 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5273 - accuracy: 0.9432 - val_loss: 0.6739 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5181 - accuracy: 0.9318 - val_loss: 0.6736 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5120 - accuracy: 0.9403 - val_loss: 0.6719 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4899 - accuracy: 0.9574 - val_loss: 0.6684 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5657 - accuracy: 0.9290 - val_loss: 0.6666 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5013 - accuracy: 0.9432 - val_loss: 0.6675 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5186 - accuracy: 0.9489 - val_loss: 0.6657 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5530 - accuracy: 0.9261 - val_loss: 0.6688 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4967 - accuracy: 0.9403 - val_loss: 0.6698 - val_accuracy: 0.8636 - lr: 4.0000e-05\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4882 - accuracy: 0.9545 - val_loss: 0.6747 - val_accuracy: 0.8068 - lr: 4.0000e-05\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5270 - accuracy: 0.9347 - val_loss: 0.6735 - val_accuracy: 0.8068 - lr: 4.0000e-05\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.9460 - val_loss: 0.6688 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4846 - accuracy: 0.9574 - val_loss: 0.6691 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5089 - accuracy: 0.9403 - val_loss: 0.6690 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4987 - accuracy: 0.9460 - val_loss: 0.6684 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5038 - accuracy: 0.9375 - val_loss: 0.6674 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5099 - accuracy: 0.9432 - val_loss: 0.6670 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5071 - accuracy: 0.9489 - val_loss: 0.6670 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.9489 - val_loss: 0.6670 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5222 - accuracy: 0.9347 - val_loss: 0.6681 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5143 - accuracy: 0.9517 - val_loss: 0.6683 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4915 - accuracy: 0.9375 - val_loss: 0.6668 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5263 - accuracy: 0.9318 - val_loss: 0.6657 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5051 - accuracy: 0.9403 - val_loss: 0.6654 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5282 - accuracy: 0.9375 - val_loss: 0.6645 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.9432 - val_loss: 0.6643 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5004 - accuracy: 0.9517 - val_loss: 0.6640 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4945 - accuracy: 0.9489 - val_loss: 0.6643 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4869 - accuracy: 0.9545 - val_loss: 0.6638 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5450 - accuracy: 0.9233 - val_loss: 0.6639 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4956 - accuracy: 0.9460 - val_loss: 0.6637 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5047 - accuracy: 0.9403 - val_loss: 0.6617 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5058 - accuracy: 0.9460 - val_loss: 0.6623 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5077 - accuracy: 0.9432 - val_loss: 0.6621 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5072 - accuracy: 0.9403 - val_loss: 0.6611 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5106 - accuracy: 0.9375 - val_loss: 0.6618 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5138 - accuracy: 0.9460 - val_loss: 0.6612 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4799 - accuracy: 0.9602 - val_loss: 0.6599 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5018 - accuracy: 0.9602 - val_loss: 0.6598 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4998 - accuracy: 0.9460 - val_loss: 0.6588 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5393 - accuracy: 0.9375 - val_loss: 0.6579 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5074 - accuracy: 0.9347 - val_loss: 0.6565 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4884 - accuracy: 0.9602 - val_loss: 0.6571 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5132 - accuracy: 0.9205 - val_loss: 0.6567 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4793 - accuracy: 0.9545 - val_loss: 0.6567 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5132 - accuracy: 0.9432 - val_loss: 0.6573 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4799 - accuracy: 0.9545 - val_loss: 0.6569 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4868 - accuracy: 0.9489 - val_loss: 0.6563 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4930 - accuracy: 0.9545 - val_loss: 0.6547 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.9318 - val_loss: 0.6530 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4952 - accuracy: 0.9545 - val_loss: 0.6521 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5080 - accuracy: 0.9375 - val_loss: 0.6531 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5348 - accuracy: 0.9290 - val_loss: 0.6540 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4927 - accuracy: 0.9489 - val_loss: 0.6543 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5391 - accuracy: 0.9347 - val_loss: 0.6542 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4944 - accuracy: 0.9659 - val_loss: 0.6559 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4973 - accuracy: 0.9347 - val_loss: 0.6573 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4763 - accuracy: 0.9574 - val_loss: 0.6571 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4914 - accuracy: 0.9489 - val_loss: 0.6578 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5210 - accuracy: 0.9205 - val_loss: 0.6564 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4975 - accuracy: 0.9517 - val_loss: 0.6549 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5146 - accuracy: 0.9375 - val_loss: 0.6538 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.9347 - val_loss: 0.6540 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.5014 - accuracy: 0.9403 - val_loss: 0.6542 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4808 - accuracy: 0.9517 - val_loss: 0.6534 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4994 - accuracy: 0.9403 - val_loss: 0.6541 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4926 - accuracy: 0.9545 - val_loss: 0.6540 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4932 - accuracy: 0.9489 - val_loss: 0.6540 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5379 - accuracy: 0.9290 - val_loss: 0.6542 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4895 - accuracy: 0.9489 - val_loss: 0.6527 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4723 - accuracy: 0.9545 - val_loss: 0.6519 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5052 - accuracy: 0.9489 - val_loss: 0.6513 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4993 - accuracy: 0.9517 - val_loss: 0.6508 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.4908 - accuracy: 0.9517 - val_loss: 0.6510 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4842 - accuracy: 0.9631 - val_loss: 0.6517 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.4729 - accuracy: 0.9545 - val_loss: 0.6513 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4930 - accuracy: 0.9517 - val_loss: 0.6507 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "Optimal threshold: 0.46\n",
            "Confusion Matrix:\n",
            "[[37  7]\n",
            " [ 3 41]]\n",
            "Fold 2\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 35ms/step - loss: 4.1916 - accuracy: 0.5284 - val_loss: 3.7892 - val_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8624 - accuracy: 0.5938 - val_loss: 3.7369 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.7968 - accuracy: 0.6364 - val_loss: 3.6783 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.6679 - accuracy: 0.6392 - val_loss: 3.6189 - val_accuracy: 0.5909 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.5968 - accuracy: 0.6562 - val_loss: 3.5601 - val_accuracy: 0.5795 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.4845 - accuracy: 0.6847 - val_loss: 3.4934 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.4606 - accuracy: 0.6818 - val_loss: 3.4282 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.3654 - accuracy: 0.7017 - val_loss: 3.3645 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.3335 - accuracy: 0.6989 - val_loss: 3.2962 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.1989 - accuracy: 0.7102 - val_loss: 3.2317 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 3.1782 - accuracy: 0.7415 - val_loss: 3.1643 - val_accuracy: 0.6818 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.1240 - accuracy: 0.7330 - val_loss: 3.1019 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.9827 - accuracy: 0.7358 - val_loss: 3.0361 - val_accuracy: 0.6818 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.9315 - accuracy: 0.7443 - val_loss: 2.9616 - val_accuracy: 0.6818 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.8244 - accuracy: 0.7926 - val_loss: 2.9024 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.7879 - accuracy: 0.7528 - val_loss: 2.8422 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.7299 - accuracy: 0.7955 - val_loss: 2.7770 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.6642 - accuracy: 0.7727 - val_loss: 2.7067 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.5831 - accuracy: 0.7983 - val_loss: 2.6407 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.5245 - accuracy: 0.7983 - val_loss: 2.5774 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.4064 - accuracy: 0.8239 - val_loss: 2.5218 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.4211 - accuracy: 0.7955 - val_loss: 2.4581 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.3142 - accuracy: 0.8295 - val_loss: 2.3881 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3139 - accuracy: 0.7983 - val_loss: 2.3342 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.2310 - accuracy: 0.8182 - val_loss: 2.2683 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1881 - accuracy: 0.8239 - val_loss: 2.1979 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1596 - accuracy: 0.8125 - val_loss: 2.1436 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1009 - accuracy: 0.8352 - val_loss: 2.0861 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0483 - accuracy: 0.8466 - val_loss: 2.0476 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.9808 - accuracy: 0.8523 - val_loss: 1.9951 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.9237 - accuracy: 0.8267 - val_loss: 1.9406 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.8523 - accuracy: 0.8466 - val_loss: 1.8863 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.8722 - accuracy: 0.8381 - val_loss: 1.8422 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.8045 - accuracy: 0.8693 - val_loss: 1.7752 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.7417 - accuracy: 0.8523 - val_loss: 1.7331 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.6994 - accuracy: 0.8551 - val_loss: 1.6890 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.6475 - accuracy: 0.8580 - val_loss: 1.6594 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.6558 - accuracy: 0.8665 - val_loss: 1.6136 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.6123 - accuracy: 0.8608 - val_loss: 1.5768 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.6100 - accuracy: 0.8494 - val_loss: 1.5472 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.5067 - accuracy: 0.8722 - val_loss: 1.5112 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5179 - accuracy: 0.8551 - val_loss: 1.4515 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4780 - accuracy: 0.8523 - val_loss: 1.4220 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4251 - accuracy: 0.8438 - val_loss: 1.3872 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3448 - accuracy: 0.8835 - val_loss: 1.3543 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3846 - accuracy: 0.8722 - val_loss: 1.3409 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.2788 - accuracy: 0.8949 - val_loss: 1.2990 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.2916 - accuracy: 0.8864 - val_loss: 1.2587 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2841 - accuracy: 0.8551 - val_loss: 1.2333 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1672 - accuracy: 0.9119 - val_loss: 1.2079 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1962 - accuracy: 0.9034 - val_loss: 1.1847 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2178 - accuracy: 0.8608 - val_loss: 1.1673 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1269 - accuracy: 0.8949 - val_loss: 1.1661 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1000 - accuracy: 0.8949 - val_loss: 1.1388 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0858 - accuracy: 0.8977 - val_loss: 1.1093 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0831 - accuracy: 0.8864 - val_loss: 1.0919 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0997 - accuracy: 0.8608 - val_loss: 1.0341 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0543 - accuracy: 0.8750 - val_loss: 1.0832 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0005 - accuracy: 0.8778 - val_loss: 1.0184 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0024 - accuracy: 0.8750 - val_loss: 0.9892 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0182 - accuracy: 0.8722 - val_loss: 0.9721 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9675 - accuracy: 0.8778 - val_loss: 0.9258 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9091 - accuracy: 0.9062 - val_loss: 0.9539 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8828 - accuracy: 0.9091 - val_loss: 0.9495 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9110 - accuracy: 0.8920 - val_loss: 0.9674 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8863 - accuracy: 0.8892 - val_loss: 0.8716 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8850 - accuracy: 0.8920 - val_loss: 0.8648 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8640 - accuracy: 0.8835 - val_loss: 0.8443 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8009 - accuracy: 0.9205 - val_loss: 0.8679 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8044 - accuracy: 0.9176 - val_loss: 0.8273 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7586 - accuracy: 0.9261 - val_loss: 0.8291 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8074 - accuracy: 0.8920 - val_loss: 0.8270 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7781 - accuracy: 0.9176 - val_loss: 0.7925 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7713 - accuracy: 0.8977 - val_loss: 0.8396 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7937 - accuracy: 0.8778 - val_loss: 0.8205 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7620 - accuracy: 0.8807 - val_loss: 0.7816 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7358 - accuracy: 0.9062 - val_loss: 0.7799 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7174 - accuracy: 0.9006 - val_loss: 0.7300 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7060 - accuracy: 0.8920 - val_loss: 0.7148 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6862 - accuracy: 0.9062 - val_loss: 0.7058 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6480 - accuracy: 0.9062 - val_loss: 0.7459 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6749 - accuracy: 0.9091 - val_loss: 0.7174 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6613 - accuracy: 0.8977 - val_loss: 0.7314 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6975 - accuracy: 0.9034 - val_loss: 0.6649 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6324 - accuracy: 0.9006 - val_loss: 0.7559 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6887 - accuracy: 0.8949 - val_loss: 0.7486 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6077 - accuracy: 0.9062 - val_loss: 0.7086 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5941 - accuracy: 0.9205 - val_loss: 0.6280 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5992 - accuracy: 0.9176 - val_loss: 0.6044 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6236 - accuracy: 0.9176 - val_loss: 0.6089 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5463 - accuracy: 0.9347 - val_loss: 0.6036 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5453 - accuracy: 0.9176 - val_loss: 0.6462 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.5840 - accuracy: 0.9062 - val_loss: 0.5829 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5145 - accuracy: 0.9375 - val_loss: 0.5853 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.5358 - accuracy: 0.9205 - val_loss: 0.6098 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.5625 - accuracy: 0.9034 - val_loss: 0.6250 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.5165 - accuracy: 0.9261 - val_loss: 0.6105 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4859 - accuracy: 0.9460 - val_loss: 0.5998 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4726 - accuracy: 0.9347 - val_loss: 0.6196 - val_accuracy: 0.8864 - lr: 2.0000e-04\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4751 - accuracy: 0.9403 - val_loss: 0.6002 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4855 - accuracy: 0.9176 - val_loss: 0.5694 - val_accuracy: 0.9091 - lr: 2.0000e-04\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4660 - accuracy: 0.9233 - val_loss: 0.5809 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4853 - accuracy: 0.9318 - val_loss: 0.6021 - val_accuracy: 0.8864 - lr: 2.0000e-04\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4765 - accuracy: 0.9347 - val_loss: 0.5885 - val_accuracy: 0.8864 - lr: 2.0000e-04\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.5078 - accuracy: 0.9290 - val_loss: 0.5876 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4507 - accuracy: 0.9489 - val_loss: 0.6027 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4614 - accuracy: 0.9489 - val_loss: 0.6057 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4445 - accuracy: 0.9517 - val_loss: 0.6075 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.4869 - accuracy: 0.9148 - val_loss: 0.6079 - val_accuracy: 0.8864 - lr: 4.0000e-05\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4795 - accuracy: 0.9318 - val_loss: 0.6067 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4721 - accuracy: 0.9403 - val_loss: 0.6044 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.4369 - accuracy: 0.9574 - val_loss: 0.6054 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4537 - accuracy: 0.9489 - val_loss: 0.6055 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4694 - accuracy: 0.9290 - val_loss: 0.6052 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4279 - accuracy: 0.9432 - val_loss: 0.6060 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.4804 - accuracy: 0.9318 - val_loss: 0.6060 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4539 - accuracy: 0.9517 - val_loss: 0.6067 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.9517 - val_loss: 0.6080 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4143 - accuracy: 0.9574 - val_loss: 0.6083 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.9659 - val_loss: 0.6080 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4392 - accuracy: 0.9517 - val_loss: 0.6075 - val_accuracy: 0.8864 - lr: 1.0000e-05\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "Optimal threshold: 0.18\n",
            "Confusion Matrix:\n",
            "[[41  3]\n",
            " [ 3 41]]\n",
            "Fold 3\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 34ms/step - loss: 4.1675 - accuracy: 0.5028 - val_loss: 3.8183 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.9732 - accuracy: 0.5909 - val_loss: 3.7528 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.8033 - accuracy: 0.6108 - val_loss: 3.6925 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.7468 - accuracy: 0.6051 - val_loss: 3.6296 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.6145 - accuracy: 0.6676 - val_loss: 3.5681 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.4691 - accuracy: 0.6705 - val_loss: 3.5050 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.4556 - accuracy: 0.7017 - val_loss: 3.4386 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.3288 - accuracy: 0.7216 - val_loss: 3.3771 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.2747 - accuracy: 0.7216 - val_loss: 3.3066 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.1631 - accuracy: 0.7670 - val_loss: 3.2421 - val_accuracy: 0.6364 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.1378 - accuracy: 0.7188 - val_loss: 3.1795 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.0637 - accuracy: 0.7358 - val_loss: 3.1083 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.9761 - accuracy: 0.7528 - val_loss: 3.0338 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.8892 - accuracy: 0.7784 - val_loss: 2.9709 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.7979 - accuracy: 0.8040 - val_loss: 2.9136 - val_accuracy: 0.6477 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.7586 - accuracy: 0.7784 - val_loss: 2.8590 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.6472 - accuracy: 0.8097 - val_loss: 2.7715 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.6069 - accuracy: 0.8239 - val_loss: 2.7080 - val_accuracy: 0.6591 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.5942 - accuracy: 0.8011 - val_loss: 2.6497 - val_accuracy: 0.6477 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.5017 - accuracy: 0.8153 - val_loss: 2.5806 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.4071 - accuracy: 0.8182 - val_loss: 2.5154 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.3622 - accuracy: 0.8409 - val_loss: 2.4357 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3445 - accuracy: 0.7955 - val_loss: 2.3966 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3094 - accuracy: 0.8040 - val_loss: 2.3324 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.1908 - accuracy: 0.8295 - val_loss: 2.3005 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.1186 - accuracy: 0.8409 - val_loss: 2.2541 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0708 - accuracy: 0.8381 - val_loss: 2.1835 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2.0380 - accuracy: 0.8381 - val_loss: 2.1497 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.9966 - accuracy: 0.8409 - val_loss: 2.0920 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.9082 - accuracy: 0.8608 - val_loss: 2.0134 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.8554 - accuracy: 0.8750 - val_loss: 1.9792 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.8344 - accuracy: 0.8551 - val_loss: 1.9522 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7779 - accuracy: 0.8722 - val_loss: 1.8591 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.7456 - accuracy: 0.8608 - val_loss: 1.8410 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7588 - accuracy: 0.8466 - val_loss: 1.8498 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6600 - accuracy: 0.8636 - val_loss: 1.7498 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.6400 - accuracy: 0.8693 - val_loss: 1.6924 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.5628 - accuracy: 0.8949 - val_loss: 1.7605 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5102 - accuracy: 0.8977 - val_loss: 1.6043 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4990 - accuracy: 0.8750 - val_loss: 1.5543 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.5013 - accuracy: 0.8494 - val_loss: 1.5536 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4282 - accuracy: 0.8835 - val_loss: 1.5037 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4350 - accuracy: 0.8693 - val_loss: 1.4517 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4334 - accuracy: 0.8438 - val_loss: 1.4212 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.3561 - accuracy: 0.8920 - val_loss: 1.3631 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2785 - accuracy: 0.8864 - val_loss: 1.3710 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2791 - accuracy: 0.8778 - val_loss: 1.3183 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2529 - accuracy: 0.8892 - val_loss: 1.2937 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.2406 - accuracy: 0.8892 - val_loss: 1.2911 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.2117 - accuracy: 0.8920 - val_loss: 1.3166 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1606 - accuracy: 0.8778 - val_loss: 1.2185 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1820 - accuracy: 0.8977 - val_loss: 1.2045 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.1352 - accuracy: 0.9006 - val_loss: 1.1376 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0827 - accuracy: 0.8892 - val_loss: 1.1609 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0854 - accuracy: 0.8722 - val_loss: 1.1058 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0297 - accuracy: 0.8977 - val_loss: 1.0622 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9629 - accuracy: 0.9290 - val_loss: 1.0536 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9575 - accuracy: 0.9290 - val_loss: 1.0518 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.9729 - accuracy: 0.8977 - val_loss: 1.0241 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9319 - accuracy: 0.9233 - val_loss: 0.9912 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9534 - accuracy: 0.9091 - val_loss: 1.0237 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9222 - accuracy: 0.8949 - val_loss: 0.9793 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9655 - accuracy: 0.8892 - val_loss: 0.9483 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8999 - accuracy: 0.9062 - val_loss: 0.9796 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8457 - accuracy: 0.9205 - val_loss: 0.8913 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.7911 - accuracy: 0.9517 - val_loss: 0.8906 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.9092 - accuracy: 0.8693 - val_loss: 0.8665 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.8020 - accuracy: 0.9148 - val_loss: 0.8664 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.7935 - accuracy: 0.9233 - val_loss: 0.8509 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.7615 - accuracy: 0.9290 - val_loss: 0.8192 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.7545 - accuracy: 0.9261 - val_loss: 0.8017 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7711 - accuracy: 0.9091 - val_loss: 0.8046 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.7143 - accuracy: 0.9176 - val_loss: 0.7915 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.7659 - accuracy: 0.8977 - val_loss: 0.8065 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.7533 - accuracy: 0.9091 - val_loss: 0.7511 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8004 - accuracy: 0.8722 - val_loss: 0.7414 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6734 - accuracy: 0.9318 - val_loss: 0.7353 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6583 - accuracy: 0.9403 - val_loss: 0.7296 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6456 - accuracy: 0.9375 - val_loss: 0.8721 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.7186 - accuracy: 0.8920 - val_loss: 0.7390 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.6656 - accuracy: 0.9006 - val_loss: 0.6947 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.6653 - accuracy: 0.9148 - val_loss: 0.6907 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6096 - accuracy: 0.9290 - val_loss: 0.7062 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5917 - accuracy: 0.9432 - val_loss: 0.7089 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6491 - accuracy: 0.8920 - val_loss: 0.6757 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6049 - accuracy: 0.9148 - val_loss: 0.6783 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6571 - accuracy: 0.8977 - val_loss: 0.7087 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.6233 - accuracy: 0.9062 - val_loss: 0.6786 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5657 - accuracy: 0.9318 - val_loss: 0.7017 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.5958 - accuracy: 0.9062 - val_loss: 0.6780 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5508 - accuracy: 0.9148 - val_loss: 0.6672 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5441 - accuracy: 0.9318 - val_loss: 0.6536 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5655 - accuracy: 0.9176 - val_loss: 0.6542 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5385 - accuracy: 0.9318 - val_loss: 0.6492 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5422 - accuracy: 0.9432 - val_loss: 0.6452 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.5279 - accuracy: 0.9517 - val_loss: 0.6435 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.5312 - accuracy: 0.9347 - val_loss: 0.6377 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5706 - accuracy: 0.9290 - val_loss: 0.6330 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5049 - accuracy: 0.9489 - val_loss: 0.6404 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.9432 - val_loss: 0.6350 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4665 - accuracy: 0.9631 - val_loss: 0.6326 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4894 - accuracy: 0.9403 - val_loss: 0.6293 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4771 - accuracy: 0.9489 - val_loss: 0.6336 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4836 - accuracy: 0.9432 - val_loss: 0.6330 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4923 - accuracy: 0.9460 - val_loss: 0.6225 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4708 - accuracy: 0.9574 - val_loss: 0.6171 - val_accuracy: 0.8864 - lr: 2.0000e-04\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4659 - accuracy: 0.9574 - val_loss: 0.6180 - val_accuracy: 0.8864 - lr: 2.0000e-04\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4935 - accuracy: 0.9432 - val_loss: 0.6421 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5055 - accuracy: 0.9432 - val_loss: 0.6562 - val_accuracy: 0.8636 - lr: 2.0000e-04\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5013 - accuracy: 0.9347 - val_loss: 0.6496 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4831 - accuracy: 0.9460 - val_loss: 0.6498 - val_accuracy: 0.8750 - lr: 2.0000e-04\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4666 - accuracy: 0.9489 - val_loss: 0.6515 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4562 - accuracy: 0.9602 - val_loss: 0.6505 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4532 - accuracy: 0.9602 - val_loss: 0.6454 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4344 - accuracy: 0.9744 - val_loss: 0.6400 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4464 - accuracy: 0.9631 - val_loss: 0.6389 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.9489 - val_loss: 0.6391 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5056 - accuracy: 0.9347 - val_loss: 0.6394 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4642 - accuracy: 0.9517 - val_loss: 0.6406 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5016 - accuracy: 0.9403 - val_loss: 0.6422 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4785 - accuracy: 0.9489 - val_loss: 0.6441 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4454 - accuracy: 0.9574 - val_loss: 0.6464 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.9489 - val_loss: 0.6480 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.9631 - val_loss: 0.6478 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.4862 - accuracy: 0.9489 - val_loss: 0.6484 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.9574 - val_loss: 0.6496 - val_accuracy: 0.8636 - lr: 1.0000e-05\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Optimal threshold: 0.74\n",
            "Confusion Matrix:\n",
            "[[40  4]\n",
            " [ 5 39]]\n",
            "Fold 4\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 36ms/step - loss: 4.5120 - accuracy: 0.5085 - val_loss: 3.8369 - val_accuracy: 0.5341 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.1429 - accuracy: 0.5938 - val_loss: 3.7835 - val_accuracy: 0.5795 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 4.0111 - accuracy: 0.6364 - val_loss: 3.7553 - val_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.8437 - accuracy: 0.6903 - val_loss: 3.7258 - val_accuracy: 0.4886 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.7955 - accuracy: 0.6705 - val_loss: 3.6902 - val_accuracy: 0.4886 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 3.8529 - accuracy: 0.6562 - val_loss: 3.6491 - val_accuracy: 0.4886 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.6685 - accuracy: 0.6960 - val_loss: 3.6035 - val_accuracy: 0.4886 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.6192 - accuracy: 0.7017 - val_loss: 3.5693 - val_accuracy: 0.4886 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.5137 - accuracy: 0.7074 - val_loss: 3.5212 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.4617 - accuracy: 0.7500 - val_loss: 3.4709 - val_accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.3837 - accuracy: 0.7216 - val_loss: 3.4236 - val_accuracy: 0.5568 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.3168 - accuracy: 0.7386 - val_loss: 3.3763 - val_accuracy: 0.5568 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.2563 - accuracy: 0.7557 - val_loss: 3.3324 - val_accuracy: 0.6023 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.2061 - accuracy: 0.7727 - val_loss: 3.2784 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.1679 - accuracy: 0.7528 - val_loss: 3.2311 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 3.1326 - accuracy: 0.7784 - val_loss: 3.1803 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 3.1244 - accuracy: 0.7386 - val_loss: 3.1414 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 3.0136 - accuracy: 0.7585 - val_loss: 3.0874 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.9229 - accuracy: 0.7898 - val_loss: 3.0342 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.9155 - accuracy: 0.7955 - val_loss: 2.9913 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.8740 - accuracy: 0.7727 - val_loss: 2.9462 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.8349 - accuracy: 0.7756 - val_loss: 2.8863 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.7728 - accuracy: 0.7983 - val_loss: 2.8473 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.7427 - accuracy: 0.7869 - val_loss: 2.8076 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.7033 - accuracy: 0.7699 - val_loss: 2.7422 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.6284 - accuracy: 0.7812 - val_loss: 2.6907 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.6277 - accuracy: 0.7756 - val_loss: 2.6291 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.5287 - accuracy: 0.8267 - val_loss: 2.6004 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 2.4697 - accuracy: 0.8438 - val_loss: 2.5684 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4128 - accuracy: 0.8381 - val_loss: 2.5327 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.4319 - accuracy: 0.8125 - val_loss: 2.4962 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.3257 - accuracy: 0.8466 - val_loss: 2.4542 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.2883 - accuracy: 0.8381 - val_loss: 2.3744 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.2497 - accuracy: 0.8466 - val_loss: 2.3203 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.2133 - accuracy: 0.8466 - val_loss: 2.2950 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.1938 - accuracy: 0.8239 - val_loss: 2.2381 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2.1314 - accuracy: 0.8409 - val_loss: 2.1586 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1357 - accuracy: 0.8097 - val_loss: 2.1105 - val_accuracy: 0.7955 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.0974 - accuracy: 0.8466 - val_loss: 2.1110 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2.0646 - accuracy: 0.8267 - val_loss: 2.0423 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.9667 - accuracy: 0.8608 - val_loss: 2.0017 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.9845 - accuracy: 0.8466 - val_loss: 1.9821 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.8836 - accuracy: 0.8693 - val_loss: 1.9116 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.9298 - accuracy: 0.8295 - val_loss: 1.8718 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 1.8686 - accuracy: 0.8466 - val_loss: 1.8300 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.8511 - accuracy: 0.8438 - val_loss: 1.8116 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.7880 - accuracy: 0.8523 - val_loss: 1.7688 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.7503 - accuracy: 0.8580 - val_loss: 1.7325 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.7477 - accuracy: 0.8466 - val_loss: 1.6980 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.6789 - accuracy: 0.8722 - val_loss: 1.6673 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.6288 - accuracy: 0.8864 - val_loss: 1.6519 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.6605 - accuracy: 0.8523 - val_loss: 1.6203 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 1.6275 - accuracy: 0.8750 - val_loss: 1.6138 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.5533 - accuracy: 0.8778 - val_loss: 1.5925 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.5432 - accuracy: 0.8693 - val_loss: 1.5477 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.5240 - accuracy: 0.8778 - val_loss: 1.5407 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.4582 - accuracy: 0.8665 - val_loss: 1.5153 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 1.5332 - accuracy: 0.8608 - val_loss: 1.4771 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.4109 - accuracy: 0.8636 - val_loss: 1.4198 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.4233 - accuracy: 0.8551 - val_loss: 1.4173 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.4004 - accuracy: 0.8636 - val_loss: 1.4223 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.3777 - accuracy: 0.8551 - val_loss: 1.3644 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.3327 - accuracy: 0.8693 - val_loss: 1.3359 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.3126 - accuracy: 0.8807 - val_loss: 1.3122 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.2771 - accuracy: 0.8722 - val_loss: 1.2902 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 1.2899 - accuracy: 0.8551 - val_loss: 1.2723 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.2544 - accuracy: 0.8722 - val_loss: 1.2309 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.2018 - accuracy: 0.9062 - val_loss: 1.2367 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.1928 - accuracy: 0.8892 - val_loss: 1.2032 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 1.1659 - accuracy: 0.8750 - val_loss: 1.1964 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1605 - accuracy: 0.8693 - val_loss: 1.1798 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1182 - accuracy: 0.9006 - val_loss: 1.1744 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0882 - accuracy: 0.9290 - val_loss: 1.1226 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0886 - accuracy: 0.9034 - val_loss: 1.0978 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0518 - accuracy: 0.9091 - val_loss: 1.0900 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1158 - accuracy: 0.8892 - val_loss: 1.0911 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0699 - accuracy: 0.8778 - val_loss: 1.1274 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.0099 - accuracy: 0.9119 - val_loss: 1.1058 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.9652 - accuracy: 0.9034 - val_loss: 1.0483 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.0208 - accuracy: 0.8722 - val_loss: 1.0295 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9665 - accuracy: 0.8977 - val_loss: 1.0034 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.9067 - accuracy: 0.9034 - val_loss: 0.9494 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.9177 - accuracy: 0.8977 - val_loss: 0.9470 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9293 - accuracy: 0.8977 - val_loss: 0.9608 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9081 - accuracy: 0.8807 - val_loss: 0.9621 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9111 - accuracy: 0.9062 - val_loss: 0.9095 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9041 - accuracy: 0.8920 - val_loss: 0.9527 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8997 - accuracy: 0.8864 - val_loss: 0.9342 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8805 - accuracy: 0.8807 - val_loss: 0.8943 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8657 - accuracy: 0.8977 - val_loss: 0.9170 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8441 - accuracy: 0.9006 - val_loss: 0.9296 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8378 - accuracy: 0.8920 - val_loss: 0.9044 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.8004 - accuracy: 0.9091 - val_loss: 0.8916 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7782 - accuracy: 0.8949 - val_loss: 0.9252 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8138 - accuracy: 0.9034 - val_loss: 0.8737 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7432 - accuracy: 0.9176 - val_loss: 0.8559 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7857 - accuracy: 0.8892 - val_loss: 0.8681 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7666 - accuracy: 0.8864 - val_loss: 0.8824 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.7007 - accuracy: 0.9261 - val_loss: 0.8334 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7599 - accuracy: 0.8892 - val_loss: 0.8066 - val_accuracy: 0.9318 - lr: 0.0010\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7137 - accuracy: 0.9119 - val_loss: 0.8339 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7508 - accuracy: 0.8977 - val_loss: 0.7790 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7113 - accuracy: 0.8949 - val_loss: 0.7496 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6930 - accuracy: 0.9148 - val_loss: 0.7472 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.9034 - val_loss: 0.7457 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6847 - accuracy: 0.9148 - val_loss: 0.7586 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6813 - accuracy: 0.8892 - val_loss: 0.7435 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6406 - accuracy: 0.9006 - val_loss: 0.7654 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6284 - accuracy: 0.9261 - val_loss: 0.7464 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.5871 - accuracy: 0.9517 - val_loss: 0.7245 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6001 - accuracy: 0.9261 - val_loss: 0.7529 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6028 - accuracy: 0.9148 - val_loss: 0.7538 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6025 - accuracy: 0.9119 - val_loss: 0.7340 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5861 - accuracy: 0.9205 - val_loss: 0.7168 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6594 - accuracy: 0.8949 - val_loss: 0.7429 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5737 - accuracy: 0.9261 - val_loss: 0.7359 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5662 - accuracy: 0.9290 - val_loss: 0.7763 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5560 - accuracy: 0.9233 - val_loss: 0.7534 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5523 - accuracy: 0.9290 - val_loss: 0.7161 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5688 - accuracy: 0.9006 - val_loss: 0.6515 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5710 - accuracy: 0.9176 - val_loss: 0.6712 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5226 - accuracy: 0.9347 - val_loss: 0.6711 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.8977 - val_loss: 0.6980 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5564 - accuracy: 0.8949 - val_loss: 0.6933 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5255 - accuracy: 0.9290 - val_loss: 0.6673 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5037 - accuracy: 0.9290 - val_loss: 0.6672 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5011 - accuracy: 0.9375 - val_loss: 0.6565 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4682 - accuracy: 0.9432 - val_loss: 0.6559 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.5306 - accuracy: 0.9176 - val_loss: 0.6613 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4970 - accuracy: 0.9176 - val_loss: 0.6593 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5172 - accuracy: 0.9233 - val_loss: 0.6626 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4833 - accuracy: 0.9403 - val_loss: 0.6666 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5025 - accuracy: 0.9261 - val_loss: 0.6678 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4759 - accuracy: 0.9347 - val_loss: 0.6676 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.5380 - accuracy: 0.9091 - val_loss: 0.6693 - val_accuracy: 0.8977 - lr: 4.0000e-05\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4672 - accuracy: 0.9460 - val_loss: 0.6711 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4976 - accuracy: 0.9176 - val_loss: 0.6728 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4753 - accuracy: 0.9290 - val_loss: 0.6740 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.4803 - accuracy: 0.9375 - val_loss: 0.6751 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.4990 - accuracy: 0.9347 - val_loss: 0.6747 - val_accuracy: 0.8977 - lr: 1.0000e-05\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "Optimal threshold: 0.22\n",
            "Confusion Matrix:\n",
            "[[40  4]\n",
            " [ 3 41]]\n",
            "Fold 5\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 3s 50ms/step - loss: 4.2149 - accuracy: 0.5199 - val_loss: 3.8392 - val_accuracy: 0.5682 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 4.0610 - accuracy: 0.5710 - val_loss: 3.7850 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.8846 - accuracy: 0.6591 - val_loss: 3.7278 - val_accuracy: 0.6705 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 3.8771 - accuracy: 0.6562 - val_loss: 3.6756 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.8562 - accuracy: 0.6392 - val_loss: 3.6142 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.6866 - accuracy: 0.6648 - val_loss: 3.5576 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 3.5326 - accuracy: 0.7102 - val_loss: 3.5057 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.4789 - accuracy: 0.7102 - val_loss: 3.4556 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.4741 - accuracy: 0.7074 - val_loss: 3.3973 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 3.4234 - accuracy: 0.7102 - val_loss: 3.3428 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.2411 - accuracy: 0.7330 - val_loss: 3.2810 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 3.2900 - accuracy: 0.7074 - val_loss: 3.2297 - val_accuracy: 0.7045 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 3.1769 - accuracy: 0.7528 - val_loss: 3.1779 - val_accuracy: 0.6932 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.0682 - accuracy: 0.7926 - val_loss: 3.1216 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 3.0364 - accuracy: 0.7670 - val_loss: 3.0549 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 2.9963 - accuracy: 0.7585 - val_loss: 2.9926 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 2.8723 - accuracy: 0.7926 - val_loss: 2.9338 - val_accuracy: 0.7159 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 2.9126 - accuracy: 0.7670 - val_loss: 2.8759 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 2.8805 - accuracy: 0.7415 - val_loss: 2.8249 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 2.7666 - accuracy: 0.7670 - val_loss: 2.7800 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 2.7643 - accuracy: 0.7472 - val_loss: 2.7267 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 2.6786 - accuracy: 0.7869 - val_loss: 2.6870 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 2.5824 - accuracy: 0.7983 - val_loss: 2.6442 - val_accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.6136 - accuracy: 0.7756 - val_loss: 2.5867 - val_accuracy: 0.7386 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.5496 - accuracy: 0.7983 - val_loss: 2.5133 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.4354 - accuracy: 0.8153 - val_loss: 2.4659 - val_accuracy: 0.7614 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.3834 - accuracy: 0.8210 - val_loss: 2.4116 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.3515 - accuracy: 0.8153 - val_loss: 2.3486 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 2.2529 - accuracy: 0.8636 - val_loss: 2.2974 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.2479 - accuracy: 0.8267 - val_loss: 2.2599 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.2691 - accuracy: 0.7955 - val_loss: 2.1971 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.1986 - accuracy: 0.8040 - val_loss: 2.1561 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 2.1051 - accuracy: 0.8409 - val_loss: 2.1230 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 2.1121 - accuracy: 0.8153 - val_loss: 2.0877 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 2.0316 - accuracy: 0.8438 - val_loss: 2.0407 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.9749 - accuracy: 0.8693 - val_loss: 1.9782 - val_accuracy: 0.8295 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.9814 - accuracy: 0.8239 - val_loss: 1.9283 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.8931 - accuracy: 0.8580 - val_loss: 1.8915 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.9293 - accuracy: 0.8381 - val_loss: 1.8649 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.8219 - accuracy: 0.8438 - val_loss: 1.8663 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.8466 - accuracy: 0.8210 - val_loss: 1.8082 - val_accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7844 - accuracy: 0.8551 - val_loss: 1.7528 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.7324 - accuracy: 0.8608 - val_loss: 1.7135 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.7222 - accuracy: 0.8580 - val_loss: 1.7039 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.6825 - accuracy: 0.8523 - val_loss: 1.6632 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.6269 - accuracy: 0.8920 - val_loss: 1.6420 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.5994 - accuracy: 0.8551 - val_loss: 1.6050 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.6140 - accuracy: 0.8466 - val_loss: 1.5591 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.5499 - accuracy: 0.8551 - val_loss: 1.5329 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.4990 - accuracy: 0.8722 - val_loss: 1.5118 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.4611 - accuracy: 0.8636 - val_loss: 1.4398 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.4561 - accuracy: 0.8722 - val_loss: 1.4288 - val_accuracy: 0.8409 - lr: 0.0010\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.4209 - accuracy: 0.8750 - val_loss: 1.4069 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4059 - accuracy: 0.8409 - val_loss: 1.4542 - val_accuracy: 0.8068 - lr: 0.0010\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3410 - accuracy: 0.8807 - val_loss: 1.4236 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.3492 - accuracy: 0.8580 - val_loss: 1.4161 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.2542 - accuracy: 0.9062 - val_loss: 1.3481 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.3518 - accuracy: 0.8438 - val_loss: 1.4361 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.2517 - accuracy: 0.8835 - val_loss: 1.2868 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2407 - accuracy: 0.8636 - val_loss: 1.2713 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2029 - accuracy: 0.8920 - val_loss: 1.2416 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1718 - accuracy: 0.8835 - val_loss: 1.2063 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1684 - accuracy: 0.8778 - val_loss: 1.2012 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 1.1126 - accuracy: 0.8864 - val_loss: 1.1708 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.1207 - accuracy: 0.8949 - val_loss: 1.2138 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.1217 - accuracy: 0.8665 - val_loss: 1.1861 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 1.0973 - accuracy: 0.8608 - val_loss: 1.1917 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 1.1170 - accuracy: 0.8494 - val_loss: 1.1524 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 1.0173 - accuracy: 0.8892 - val_loss: 1.1213 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9773 - accuracy: 0.9062 - val_loss: 1.0848 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9662 - accuracy: 0.9205 - val_loss: 1.1222 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9715 - accuracy: 0.8892 - val_loss: 1.0503 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9084 - accuracy: 0.9233 - val_loss: 1.0683 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.9757 - accuracy: 0.8807 - val_loss: 1.0583 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8887 - accuracy: 0.9261 - val_loss: 0.9942 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8925 - accuracy: 0.9148 - val_loss: 1.0097 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.9020 - accuracy: 0.8977 - val_loss: 1.0190 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.8731 - accuracy: 0.8977 - val_loss: 0.9941 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8313 - accuracy: 0.9119 - val_loss: 0.9742 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.8305 - accuracy: 0.8920 - val_loss: 0.9532 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.8829 - accuracy: 0.8864 - val_loss: 0.9471 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7983 - accuracy: 0.9205 - val_loss: 0.9121 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.8073 - accuracy: 0.8949 - val_loss: 0.8767 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7673 - accuracy: 0.9318 - val_loss: 0.9522 - val_accuracy: 0.8523 - lr: 0.0010\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7880 - accuracy: 0.9034 - val_loss: 0.8572 - val_accuracy: 0.8636 - lr: 0.0010\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7679 - accuracy: 0.8977 - val_loss: 0.8548 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.7340 - accuracy: 0.9318 - val_loss: 0.8557 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7210 - accuracy: 0.9176 - val_loss: 0.8406 - val_accuracy: 0.9205 - lr: 0.0010\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7446 - accuracy: 0.9034 - val_loss: 0.8248 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7379 - accuracy: 0.9006 - val_loss: 0.8380 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.9034 - val_loss: 0.8779 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7080 - accuracy: 0.9062 - val_loss: 0.8581 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6658 - accuracy: 0.9006 - val_loss: 0.8811 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.7016 - accuracy: 0.9148 - val_loss: 0.8415 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6748 - accuracy: 0.9091 - val_loss: 0.8367 - val_accuracy: 0.8977 - lr: 2.0000e-04\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6409 - accuracy: 0.9347 - val_loss: 0.8325 - val_accuracy: 0.9091 - lr: 2.0000e-04\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6270 - accuracy: 0.9432 - val_loss: 0.8365 - val_accuracy: 0.9091 - lr: 2.0000e-04\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.6425 - accuracy: 0.9261 - val_loss: 0.8293 - val_accuracy: 0.9091 - lr: 2.0000e-04\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6350 - accuracy: 0.9148 - val_loss: 0.8424 - val_accuracy: 0.9205 - lr: 2.0000e-04\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6739 - accuracy: 0.9119 - val_loss: 0.8528 - val_accuracy: 0.9205 - lr: 4.0000e-05\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6235 - accuracy: 0.9290 - val_loss: 0.8545 - val_accuracy: 0.9318 - lr: 4.0000e-05\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6055 - accuracy: 0.9290 - val_loss: 0.8542 - val_accuracy: 0.9205 - lr: 4.0000e-05\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6144 - accuracy: 0.9290 - val_loss: 0.8546 - val_accuracy: 0.9205 - lr: 4.0000e-05\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6246 - accuracy: 0.9375 - val_loss: 0.8550 - val_accuracy: 0.9205 - lr: 4.0000e-05\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6297 - accuracy: 0.9176 - val_loss: 0.8561 - val_accuracy: 0.9205 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.6007 - accuracy: 0.9347 - val_loss: 0.8578 - val_accuracy: 0.9205 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5927 - accuracy: 0.9318 - val_loss: 0.8576 - val_accuracy: 0.9205 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6128 - accuracy: 0.9318 - val_loss: 0.8584 - val_accuracy: 0.9205 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.6288 - accuracy: 0.9432 - val_loss: 0.8561 - val_accuracy: 0.9205 - lr: 1.0000e-05\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "Optimal threshold: 0.45\n",
            "Confusion Matrix:\n",
            "[[37  7]\n",
            " [ 1 43]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Results:\n",
            "Accuracy: 0.9091 (+/- 0.0161)\n",
            "Precision: 0.8928 (+/- 0.0304)\n",
            "Recall: 0.9318 (+/- 0.0287)\n",
            "F1 Score: 0.9112 (+/- 0.0152)\n",
            "\n",
            "Average Confusion Matrix:\n",
            "[[39  5]\n",
            " [ 3 41]]\n",
            "True Positives (TP): 41\n",
            "True Negatives (TN): 39\n",
            "False Positives (FP): 5\n",
            "False Negatives (FN): 3\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}